{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autocurator2_CNN_v1_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacheung/still-learning/blob/master/autocurator2_CNN_v1_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBEOUJuANrQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b856dacf-f1ab-4551-f0f2-5165fe26a658"
      },
      "source": [
        "# Import necessary libraries and set up image libraries in Google drive\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from sklearn.utils import class_weight\n",
        "import sklearn.model_selection as ms\n",
        "\n",
        "from google.colab import drive\n",
        "import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount google drive and grab images and labels names \n",
        "drive.mount('/content/gdrive')\n",
        "base_dir = \"/content/gdrive/My Drive/Colab data/trialFramesNPY/\"\n",
        "T_class = glob.glob(base_dir + \"*touchClass.mat\")\n",
        "frames = glob.glob(base_dir + \"*dataset.mat\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABj6WXPSJ84x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "base_dir = \"/content/gdrive/My Drive/Colab data/trialFramesNPY/\"\n",
        "T_class = glob.glob(base_dir + \"*touchClass.mat\")\n",
        "frames = glob.glob(base_dir + \"*dataset.mat\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tyz1Qriw2a4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed2c315f-3fae-4bbc-9146-08dcc06b9330"
      },
      "source": [
        "T_class"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPgTLRh9WKgd",
        "colab_type": "text"
      },
      "source": [
        "Cut the ends off so we can match them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXFWPKw6on2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frame_nums = []\n",
        "for i in range(len(frames)):\n",
        "  # print(i)\n",
        "  frame_nums.append(frames[i][1:-11])\n",
        "T_class_nums = [];\n",
        "for i in range(len(T_class)):\n",
        "  # print(i)\n",
        "  T_class_nums.append(T_class[i][1:-14])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71cwrQ8LIca4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7e9afd76-6f14-468f-e5ae-faacea4dde0b"
      },
      "source": [
        "T_class_nums[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'content/gdrive/My Drive/Colab data/trialFramesNPY/AH0000x000000-103_'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODnz2aJLTQew",
        "colab_type": "text"
      },
      "source": [
        "match all the label and frame files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_JezT3C_6EE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cbfe36f8-bc82-4d4f-d2ca-17f7c6f97f50"
      },
      "source": [
        "indices = []\n",
        "for k in range(len(frame_nums)):\n",
        "  indices.append([i for i, s in enumerate(T_class_nums) if frame_nums[k] in s])\n",
        "\n",
        "indices = [x for x in indices if x != []]\n",
        "T_class_reordered = []\n",
        "for k in range(len(indices)):\n",
        "    T_class_reordered.append(T_class[indices[k][0]])\n",
        "\n",
        "# test that this is matched\n",
        "print(T_class_reordered[0])\n",
        "print(frames[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab data/trialFramesNPY/AH0000x000000-35_touchClass.mat\n",
            "/content/gdrive/My Drive/Colab data/trialFramesNPY/AH0000x000000-35_dataset.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr7GDc0X3WE9",
        "colab_type": "text"
      },
      "source": [
        "load in all of the lables and also count how many data points are in each file. each file represents a trial so for us this could be anywhere between 1 and 4000 data points. most often somewhere between 200-600"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGem5Qao1cYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_Y_set = []\n",
        "frame_num_in_Y_set = []\n",
        "for cnt1 in range(len(frames)):\n",
        "  tmp2 = scipy.io.loadmat(T_class_reordered[cnt1])\n",
        "  raw_Y_set.append(tmp2['touchClass'])\n",
        "  frame_num_in_Y_set.append(len(raw_Y_set[cnt1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX1TKm3-yQrB",
        "colab_type": "text"
      },
      "source": [
        "# build_data \n",
        "to generate an image tensor and corresponding label array "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls0klmrRNy0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from psutil import virtual_memory\n",
        "import sys\n",
        "import time\n",
        "\n",
        "def build_data( x_files, y_files) :\n",
        "  to_del = 0\n",
        "  start = time.time()\n",
        "\n",
        "  cnt1 = -1;\n",
        "  mem_free = 9999\n",
        "\n",
        "  for k in range(len(y_files)):\n",
        "    cnt1 = cnt1 + 1\n",
        "    tmp1 = scipy.io.loadmat(x_files[cnt1])\n",
        "    tmp2 = scipy.io.loadmat(y_files[cnt1])\n",
        "\n",
        "    Xtmp = tmp1['finalMat']\n",
        "    Ytmp = tmp2['touchClass']\n",
        "    if cnt1==0:\n",
        "      raw_X = Xtmp\n",
        "      raw_Y = Ytmp\n",
        "    else:\n",
        "      \n",
        "      # print(raw_Y.shape)\n",
        "      # print(\"\\r\")\n",
        "      raw_X = np.concatenate((raw_X,Xtmp), axis=0)\n",
        "      raw_Y = np.concatenate((raw_Y,Ytmp), axis=0)\n",
        "    if ((time.time() - start) > 2) or cnt1>=len(x_files)-1:# update every 2 seconds or when loop ends\n",
        "      mem = virtual_memory()\n",
        "      mem_free = mem.free/1024**3;\n",
        "      start = time.time()\n",
        "\n",
        "      # print('\\b'* (to_del+2))\n",
        "      # to_print = (\"X shape = \" + str(raw_X.shape)+'\\n'+\n",
        "      #             \"Y shape = \" + str(raw_Y.shape)+'\\n'+\n",
        "      #             str(round(mem_free, 2)) + \"GB free\"+'\\n'+\n",
        "      #            \"iter \" + str(cnt1+1) + ' of ' + str(len(y_files)))\n",
        "      # print(to_print)\n",
        "      # to_del = len(to_print)\n",
        "  return raw_X, raw_Y\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qasu3Qg73pcL",
        "colab_type": "text"
      },
      "source": [
        "make a custom class to help load in the data to prevent crashing due to over using RAM \n",
        "This class will \n",
        "- chunk the files based on the total frames contained in them based on \"batch_size\" variable \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkN3VJIA5XEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class My_Custom_Generator(keras.utils.Sequence) :\n",
        "  \n",
        "  def __init__(self, file_trial_list, file_Y_list, num_in_each, batch_size) :\n",
        "    cnt = 0\n",
        "    extract_inds = []\n",
        "    # num_in_each contains the number of frames in each file I am loading, ie\n",
        "    # for trial/file 1 there are 200 frames , trial/file 2 has 215 frames etc\n",
        "    for k, elem in enumerate(num_in_each) :\n",
        "      tot_frame_nums = sum(num_in_each[cnt: k+1]) # used to test if the number of frames in \n",
        "      # all these files exceded the \"batch_size\" limit \n",
        "      if tot_frame_nums>batch_size or len(num_in_each)-1 == k: # condition met, these files together \n",
        "      # meet the max requirment to load together as a batch \n",
        "        extract_inds.append([cnt, k+1])\n",
        "        cnt = k+1 # reset to the current iter\n",
        "        if np.diff(extract_inds[-1]) > 1: # if there is more than one file then we want to take off the last file \n",
        "        # because it excedes the set number of frames\n",
        "          extract_inds[-1][-1] = extract_inds[-1][-1]-1\n",
        "          cnt = cnt-1\n",
        "    \n",
        "    file_list_chunks = []\n",
        "    file_Y_list_chunks = []\n",
        "    for i, ii in enumerate(extract_inds):\n",
        "      file_list_chunks.append(file_trial_list[ii[0]:ii[1]])\n",
        "      file_Y_list_chunks.append(file_Y_list[ii[0]:ii[1]])\n",
        "\n",
        "\n",
        "    self.file_trial_list = file_trial_list\n",
        "    self.file_Y_list = file_Y_list\n",
        "    self.batch_size = batch_size\n",
        "    self.extract_inds = extract_inds\n",
        "    self.num_in_each = num_in_each\n",
        "    self.file_list_chunks = file_list_chunks\n",
        "    self.file_Y_list_chunks = file_Y_list_chunks\n",
        "    \n",
        "    \n",
        "    # for i, ii in enumerate(extract_inds):\n",
        "    #   file_list_chunks.append(self.file_trial_list[ii[0]:ii[1]])\n",
        "    #   file_Y_list_chunks.append(self.file_Y_list[ii[0]:ii[1]])\n",
        "    \n",
        "\n",
        "  # def print_ind_frame_info(self) :\n",
        "\n",
        "  #   for i, ii in enumerate(self.extract_inds):\n",
        "  #       # num_in_each[extract_inds[i][1]:extract_inds[i][-1]]\n",
        "  #       tmp1 = self.num_in_each[self.extract_inds[i][0]: self.extract_inds[i][-1]]\n",
        "  #       print('frames in EACH of these '+str(len(tmp1)) + ' files are '+str(tmp1))\n",
        "  #       print('   frames in all of these '+ str(len(tmp1)) + ' of these files = ' + \n",
        "  #             str(sum(tmp1)) + ' which is less than batch limit of '+str(self.batch_size)+\n",
        "  #             ' unless a single files exedes this limit ')  \n",
        "    \n",
        "  def __len__(self) :\n",
        "    return len(self.extract_inds)\n",
        "  \n",
        "  # def unbunch_files(self, num_2_extract) :\n",
        "  #   xout2, yout2 = build_data(self.file_list_chunks[num_2_extract], \n",
        "  #                         self.file_Y_list_chunks[num_2_extract])\n",
        "  #   return xout2, yout2\n",
        "  def __getitem__(self, num_2_extract) :\n",
        "    raw_X, raw_Y = build_data(self.file_list_chunks[num_2_extract], \n",
        "                          self.file_Y_list_chunks[num_2_extract])\n",
        "    # return xout2, yout2\n",
        "    rgb_batch = np.repeat(raw_X[..., np.newaxis], 3, -1)\n",
        "    IMG_SIZE = 96 # All images will be resized to 160x160. This is the size of MobileNetV2 input sizes\n",
        "\n",
        "    rgb_tensor = tf.cast(rgb_batch, tf.float32) # convert to tf tensor with float32 dtypes\n",
        "    rgb_tensor = (rgb_tensor/127.5) - 1 # /127.5 = 0:2, -1 = -1:1 requirement for mobilenetV2\n",
        "    rgb_tensor = tf.image.resize(rgb_tensor, (IMG_SIZE, IMG_SIZE)) # resizing\n",
        "\n",
        "    self.IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "    samp_weights = np.mean(raw_Y)\n",
        "\n",
        "    return rgb_tensor, raw_Y\n",
        "    # batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    # batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    \n",
        "    # return np.array([\n",
        "    #         resize(imread('/content/all_images/' + str(file_name)), (80, 80, 3))\n",
        "    #            for file_name in batch_x])/255.0, np.array(batch_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7awsjgz6z_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b54a393b-7fa7-418d-c9de-40e9edbab6d5"
      },
      "source": [
        "# np.mean(raw_Y_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23432071387084852"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQKE1y9YBVyQ",
        "colab_type": "text"
      },
      "source": [
        "# 3) Feature engineering and test/train/validation splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "88LvgZIUBTXV",
        "colab": {}
      },
      "source": [
        "batch_size = 2000\n",
        "my_training_batch_generator = My_Custom_Generator(frames, T_class_reordered, frame_num_in_Y_set,  batch_size)\n",
        "my_validation_batch_generator = My_Custom_Generator(frames, T_class_reordered, frame_num_in_Y_set,  batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0LNCqs96cO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Y vectorization and class weight calculation \n",
        "to_del = 0\n",
        "start = time.time()\n",
        "\n",
        "cnt1 = -1;\n",
        "mem_free = 9999\n",
        "y_files = my_training_batch_generator.file_Y_list\n",
        "for k in range(len(y_files)):\n",
        "  cnt1 = cnt1 + 1\n",
        "  tmp2 = scipy.io.loadmat(y_files[cnt1])\n",
        "\n",
        "  Ytmp = tmp2['touchClass']\n",
        "  if cnt1==0:\n",
        "    raw_Y_2 = Ytmp\n",
        "  else:\n",
        "    raw_Y_2 = np.concatenate((raw_Y_2,Ytmp), axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIWvXzxw37a7",
        "colab_type": "text"
      },
      "source": [
        "# 4) Deploy and selection of base model\n",
        "In this section we're going to use MobileNetV2 as the base model.\n",
        "We're going to run two variations of the model.  \n",
        "a. basemodel with frozen layers and output classifer changes   \n",
        "b. basemodel with final 100 layers unfrozen to optimize prediction \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOfFjdZbqXoS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "cb0e684f-b36b-422f-e88c-aa02c6e2f167"
      },
      "source": [
        "# Create base model \n",
        "\n",
        "# First, instantiate a MobileNet V2 model pre-loaded with weights trained on ImageNet. By specifying the include_top=False argument, \n",
        "# you load a network that doesn't include the classification layers at the top, which is ideal for feature extraction\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SIZE = 96 # All images will be resized to 160x160. This is the size of MobileNetV2 input sizes\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "feature_batch = base_model.output\n",
        "print(feature_batch.shape)\n",
        "\n",
        "# Adding Classification head\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)\n",
        "\n",
        "prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)\n",
        "\n",
        "# Model Stacking\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Compile model with specific metrics\n",
        "# Metrics below are for evaluating imbalanced datasets\n",
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name = 'auc')\n",
        "]\n",
        "\n",
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=METRICS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "(None, 3, 3, 1280)\n",
            "(None, 1280)\n",
            "(None, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_96 (Model)  (None, 3, 3, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gt0G74FsB6_i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "a18cede3-57d8-4ec6-b739-142ced0968fa"
      },
      "source": [
        "# Fit model with a couple parameters\n",
        "EPOCHS = 20\n",
        "\n",
        "# Class imbalance weighting\n",
        "rebalance = class_weight.compute_class_weight('balanced',\n",
        "                                  [0, 1], raw_Y_2.flatten())\n",
        "class_weights = {i : rebalance[i] for i in range(2)}\n",
        "\n",
        "# Early stopping \n",
        "callbacks = [keras.callbacks.EarlyStopping (monitor = 'val_loss',\n",
        "                                            patience = 2)]\n",
        "\n",
        "history = model.fit(my_training_batch_generator, epochs=EPOCHS,\n",
        "              validation_data= my_validation_batch_generator,\n",
        "              callbacks = callbacks,\n",
        "              class_weight = class_weights)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "49/49 [==============================] - 184s 4s/step - loss: 0.5324 - tp: 14879.0000 - fp: 7206.0000 - tn: 62857.0000 - fn: 7014.0000 - precision: 0.6737 - recall: 0.6796 - auc: 0.8630 - val_loss: 0.4735 - val_tp: 16277.0000 - val_fp: 7048.0000 - val_tn: 63015.0000 - val_fn: 5616.0000 - val_precision: 0.6978 - val_recall: 0.7435 - val_auc: 0.9073\n",
            "Epoch 2/20\n",
            "49/49 [==============================] - 48s 987ms/step - loss: 0.4638 - tp: 16581.0000 - fp: 5611.0000 - tn: 64452.0000 - fn: 5312.0000 - precision: 0.7472 - recall: 0.7574 - auc: 0.9315 - val_loss: 0.4800 - val_tp: 19485.0000 - val_fp: 13258.0000 - val_tn: 56805.0000 - val_fn: 2408.0000 - val_precision: 0.5951 - val_recall: 0.8900 - val_auc: 0.9378\n",
            "Epoch 3/20\n",
            "49/49 [==============================] - 49s 994ms/step - loss: 0.4226 - tp: 18882.0000 - fp: 9024.0000 - tn: 61039.0000 - fn: 3011.0000 - precision: 0.6766 - recall: 0.8625 - auc: 0.9437 - val_loss: 0.3914 - val_tp: 18776.0000 - val_fp: 6164.0000 - val_tn: 63899.0000 - val_fn: 3117.0000 - val_precision: 0.7528 - val_recall: 0.8576 - val_auc: 0.9526\n",
            "Epoch 4/20\n",
            "49/49 [==============================] - 49s 992ms/step - loss: 0.3813 - tp: 19367.0000 - fp: 7221.0000 - tn: 62842.0000 - fn: 2526.0000 - precision: 0.7284 - recall: 0.8846 - auc: 0.9552 - val_loss: 0.3552 - val_tp: 19321.0000 - val_fp: 5544.0000 - val_tn: 64519.0000 - val_fn: 2572.0000 - val_precision: 0.7770 - val_recall: 0.8825 - val_auc: 0.9605\n",
            "Epoch 5/20\n",
            "49/49 [==============================] - 49s 993ms/step - loss: 0.3504 - tp: 19529.0000 - fp: 5700.0000 - tn: 64363.0000 - fn: 2364.0000 - precision: 0.7741 - recall: 0.8920 - auc: 0.9608 - val_loss: 0.3358 - val_tp: 20090.0000 - val_fp: 5826.0000 - val_tn: 64237.0000 - val_fn: 1803.0000 - val_precision: 0.7752 - val_recall: 0.9176 - val_auc: 0.9653\n",
            "Epoch 6/20\n",
            "49/49 [==============================] - 49s 991ms/step - loss: 0.3232 - tp: 20286.0000 - fp: 6108.0000 - tn: 63955.0000 - fn: 1607.0000 - precision: 0.7686 - recall: 0.9266 - auc: 0.9657 - val_loss: 0.3063 - val_tp: 20220.0000 - val_fp: 5309.0000 - val_tn: 64754.0000 - val_fn: 1673.0000 - val_precision: 0.7920 - val_recall: 0.9236 - val_auc: 0.9683\n",
            "Epoch 7/20\n",
            "49/49 [==============================] - 49s 991ms/step - loss: 0.3003 - tp: 20498.0000 - fp: 5886.0000 - tn: 64177.0000 - fn: 1395.0000 - precision: 0.7769 - recall: 0.9363 - auc: 0.9681 - val_loss: 0.2949 - val_tp: 20643.0000 - val_fp: 5618.0000 - val_tn: 64445.0000 - val_fn: 1250.0000 - val_precision: 0.7861 - val_recall: 0.9429 - val_auc: 0.9705\n",
            "Epoch 8/20\n",
            "49/49 [==============================] - 48s 987ms/step - loss: 0.2826 - tp: 20723.0000 - fp: 6022.0000 - tn: 64041.0000 - fn: 1170.0000 - precision: 0.7748 - recall: 0.9466 - auc: 0.9707 - val_loss: 0.2702 - val_tp: 20585.0000 - val_fp: 5152.0000 - val_tn: 64911.0000 - val_fn: 1308.0000 - val_precision: 0.7998 - val_recall: 0.9403 - val_auc: 0.9720\n",
            "Epoch 9/20\n",
            "49/49 [==============================] - 48s 986ms/step - loss: 0.2674 - tp: 20834.0000 - fp: 5824.0000 - tn: 64239.0000 - fn: 1059.0000 - precision: 0.7815 - recall: 0.9516 - auc: 0.9718 - val_loss: 0.2495 - val_tp: 20525.0000 - val_fp: 4803.0000 - val_tn: 65260.0000 - val_fn: 1368.0000 - val_precision: 0.8104 - val_recall: 0.9375 - val_auc: 0.9732\n",
            "Epoch 10/20\n",
            "49/49 [==============================] - 48s 988ms/step - loss: 0.2554 - tp: 20733.0000 - fp: 5411.0000 - tn: 64652.0000 - fn: 1160.0000 - precision: 0.7930 - recall: 0.9470 - auc: 0.9726 - val_loss: 0.2509 - val_tp: 20834.0000 - val_fp: 5262.0000 - val_tn: 64801.0000 - val_fn: 1059.0000 - val_precision: 0.7984 - val_recall: 0.9516 - val_auc: 0.9744\n",
            "Epoch 11/20\n",
            "49/49 [==============================] - 48s 988ms/step - loss: 0.2432 - tp: 20858.0000 - fp: 5418.0000 - tn: 64645.0000 - fn: 1035.0000 - precision: 0.7938 - recall: 0.9527 - auc: 0.9742 - val_loss: 0.2387 - val_tp: 20843.0000 - val_fp: 5121.0000 - val_tn: 64942.0000 - val_fn: 1050.0000 - val_precision: 0.8028 - val_recall: 0.9520 - val_auc: 0.9753\n",
            "Epoch 12/20\n",
            "49/49 [==============================] - 48s 985ms/step - loss: 0.2331 - tp: 20836.0000 - fp: 5183.0000 - tn: 64880.0000 - fn: 1057.0000 - precision: 0.8008 - recall: 0.9517 - auc: 0.9753 - val_loss: 0.2334 - val_tp: 20911.0000 - val_fp: 5200.0000 - val_tn: 64863.0000 - val_fn: 982.0000 - val_precision: 0.8009 - val_recall: 0.9551 - val_auc: 0.9762\n",
            "Epoch 13/20\n",
            "49/49 [==============================] - 48s 984ms/step - loss: 0.2253 - tp: 20934.0000 - fp: 5260.0000 - tn: 64803.0000 - fn: 959.0000 - precision: 0.7992 - recall: 0.9562 - auc: 0.9757 - val_loss: 0.2332 - val_tp: 21028.0000 - val_fp: 5428.0000 - val_tn: 64635.0000 - val_fn: 865.0000 - val_precision: 0.7948 - val_recall: 0.9605 - val_auc: 0.9771\n",
            "Epoch 14/20\n",
            "49/49 [==============================] - 48s 987ms/step - loss: 0.2179 - tp: 20985.0000 - fp: 5362.0000 - tn: 64701.0000 - fn: 908.0000 - precision: 0.7965 - recall: 0.9585 - auc: 0.9768 - val_loss: 0.2258 - val_tp: 21037.0000 - val_fp: 5351.0000 - val_tn: 64712.0000 - val_fn: 856.0000 - val_precision: 0.7972 - val_recall: 0.9609 - val_auc: 0.9778\n",
            "Epoch 15/20\n",
            "49/49 [==============================] - 48s 981ms/step - loss: 0.2111 - tp: 21047.0000 - fp: 5418.0000 - tn: 64645.0000 - fn: 846.0000 - precision: 0.7953 - recall: 0.9614 - auc: 0.9775 - val_loss: 0.2113 - val_tp: 20972.0000 - val_fp: 5003.0000 - val_tn: 65060.0000 - val_fn: 921.0000 - val_precision: 0.8074 - val_recall: 0.9579 - val_auc: 0.9784\n",
            "Epoch 16/20\n",
            "49/49 [==============================] - 48s 987ms/step - loss: 0.2053 - tp: 21003.0000 - fp: 5205.0000 - tn: 64858.0000 - fn: 890.0000 - precision: 0.8014 - recall: 0.9593 - auc: 0.9782 - val_loss: 0.2087 - val_tp: 21009.0000 - val_fp: 5048.0000 - val_tn: 65015.0000 - val_fn: 884.0000 - val_precision: 0.8063 - val_recall: 0.9596 - val_auc: 0.9790\n",
            "Epoch 17/20\n",
            "49/49 [==============================] - 48s 986ms/step - loss: 0.1996 - tp: 21015.0000 - fp: 5071.0000 - tn: 64992.0000 - fn: 878.0000 - precision: 0.8056 - recall: 0.9599 - auc: 0.9787 - val_loss: 0.2108 - val_tp: 21086.0000 - val_fp: 5242.0000 - val_tn: 64821.0000 - val_fn: 807.0000 - val_precision: 0.8009 - val_recall: 0.9631 - val_auc: 0.9796\n",
            "Epoch 18/20\n",
            "49/49 [==============================] - 48s 985ms/step - loss: 0.1947 - tp: 21055.0000 - fp: 5134.0000 - tn: 64929.0000 - fn: 838.0000 - precision: 0.8040 - recall: 0.9617 - auc: 0.9795 - val_loss: 0.1971 - val_tp: 21011.0000 - val_fp: 4853.0000 - val_tn: 65210.0000 - val_fn: 882.0000 - val_precision: 0.8124 - val_recall: 0.9597 - val_auc: 0.9800\n",
            "Epoch 19/20\n",
            "49/49 [==============================] - 48s 987ms/step - loss: 0.1904 - tp: 21020.0000 - fp: 4896.0000 - tn: 65167.0000 - fn: 873.0000 - precision: 0.8111 - recall: 0.9601 - auc: 0.9798 - val_loss: 0.2000 - val_tp: 21090.0000 - val_fp: 5053.0000 - val_tn: 65010.0000 - val_fn: 803.0000 - val_precision: 0.8067 - val_recall: 0.9633 - val_auc: 0.9806\n",
            "Epoch 20/20\n",
            "49/49 [==============================] - 48s 986ms/step - loss: 0.1864 - tp: 21091.0000 - fp: 5116.0000 - tn: 64947.0000 - fn: 802.0000 - precision: 0.8048 - recall: 0.9634 - auc: 0.9802 - val_loss: 0.1931 - val_tp: 21073.0000 - val_fp: 4898.0000 - val_tn: 65165.0000 - val_fn: 820.0000 - val_precision: 0.8114 - val_recall: 0.9625 - val_auc: 0.9810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMGd5RW2VDaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "8d55657f-e743-486c-a17d-ff59e83b4e77"
      },
      "source": [
        "# Model evaluation\n",
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "def plot_metrics(history):\n",
        "  metrics =  ['loss', 'auc', 'precision', 'recall']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(2,2,n+1)\n",
        "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric],\n",
        "             color=colors[0], linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    elif metric == 'auc':\n",
        "      plt.ylim([0.8,1])\n",
        "    else:\n",
        "      plt.ylim([0,1.1])\n",
        "\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "plot_metrics(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR4oHmidBh-X",
        "colab_type": "text"
      },
      "source": [
        "# ---- DONE ---- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbjkJct_N6fw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3cd9a47-db28-4ed4-80b6-5614423a46da"
      },
      "source": [
        "model.predit()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7ff24a6a3860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUWWopCdN6mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dmatx,true_y = my_validation_batch_generator.__getitem__(1)\n",
        "\n",
        "pred_y = model.predict(dmatx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haPmWYjSOT7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix as cm\n",
        "\n",
        "cm2 = cm(true_y, pred_y>.5)\n",
        "# TN FN TP FP "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNDJW1yMRjPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perf_measure(y_actual, y_hat):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_hat)): \n",
        "        if y_actual[i]==y_hat[i]==1:\n",
        "           TP += 1\n",
        "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
        "           FP += 1\n",
        "        if y_actual[i]==y_hat[i]==0:\n",
        "           TN += 1\n",
        "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
        "           FN += 1\n",
        "\n",
        "    return(TP, FP, TN, FN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSgwdkoCQbAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t2 = true_y*2\n",
        "\n",
        "pred_binary = pred_y>.5 \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfWkx8I_VqMu",
        "colab_type": "text"
      },
      "source": [
        "create video of data types and sorted by prediction number and print the prediction number on the video to assess if there is a trend in the error type. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce215NguRrxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TP, FP, TN, FN = perf_measure(true_y, pred_binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5St6posiSYr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45036ecf-5bdb-4de7-d7c5-e7cffb80211c"
      },
      "source": [
        "TP"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "510"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPV8oZ7EQxpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa306eb6-bb0b-4573-9be2-1d53a7dbc3a8"
      },
      "source": [
        "p2[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1],\n",
              "       [-1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umtBid_i1p4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit model with a couple parameters\n",
        "EPOCHS = 20\n",
        "\n",
        "# Class imbalance weighting\n",
        "rebalance = class_weight.compute_class_weight('balanced',\n",
        "                                  [0, 1], raw_Y_2.flatten())\n",
        "class_weights = {i : rebalance[i] for i in range(2)}\n",
        "\n",
        "# Early stopping \n",
        "callbacks = [keras.callbacks.EarlyStopping (monitor = 'val_loss',\n",
        "                                            patience = 2)]\n",
        "\n",
        "history = model.fit(my_training_batch_generator, epochs=EPOCHS,\n",
        "              validation_data= my_validation_batch_generator,\n",
        "              callbacks = callbacks)\n",
        "\n",
        "\n",
        "#  can use below to see how many positive labels there are\n",
        "# np.mean(raw_Y_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuyDVv3x4yIf",
        "colab_type": "text"
      },
      "source": [
        "## 1) Data cleaning  \n",
        "In this section we're going to convert the images to the right channels and dimensions for MobileNetV2. \n",
        "\n",
        "a. many of the pre-trained models require 3 channels instead of 1  \n",
        "b. many of the pre-trained models also require specific image dimensions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYb1wnarMHNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a. 3 channel conversion - convert grayscale image (1 channel) to rgb image (3 channel) for pretrained networks\n",
        "# # REDUCING SIZE OF IMAGE TENSOR AND OTHER ARRAY TO PREVENT CRASHING FOR NOW\n",
        "\n",
        "\n",
        "# # raw_X = raw_X[0:999, :, :]\n",
        "# # raw_Y = raw_Y[0:999, :]\n",
        "# print('raw image size = ' + str(raw_X.shape))  # (64, 224, 224)\n",
        "# rgb_batch = np.repeat(raw_X[..., np.newaxis], 3, -1)\n",
        "# print('converted rgb image size = ' + str(rgb_batch.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeIVhHvshlpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rgb_batch = np.repeat(raw_X[..., np.newaxis], 3, -1)\n",
        "# IMG_SIZE = 96 # All images will be resized to 160x160. This is the size of MobileNetV2 input sizes\n",
        "\n",
        "# rgb_tensor = tf.cast(rgb_batch, tf.float32) # convert to tf tensor with float32 dtypes\n",
        "# rgb_tensor = (rgb_tensor/127.5) - 1 # /127.5 = 0:2, -1 = -1:1 requirement for mobilenetV2\n",
        "# rgb_tensor = tf.image.resize(rgb_tensor, (IMG_SIZE, IMG_SIZE)) # resizing\n",
        "\n",
        "# IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxN3zAwg3yL8",
        "colab_type": "text"
      },
      "source": [
        "# 2) Basic EDA  \n",
        "We're going to verify that the data looks good by eye. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWvMd5Mpe2t3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "b14480ae-a592-4674-bf44-5f3470097892"
      },
      "source": [
        "# Look at the distribution of classes\n",
        "fig, axs = plt.subplots(1, 3)\n",
        "axs[0].hist(raw_Y)\n",
        "axs[0].set_title('class distribution')\n",
        "axs[0].set_xticks([0,1])\n",
        "axs[0].set_xticklabels(['neg class', 'pos class'])\n",
        "axs[0].set_ylabel('number of examples')\n",
        "\n",
        "# Look at some images of positive and negative\n",
        "neg_class = [i for i, val in enumerate(raw_Y) if val==0]\n",
        "pos_class = [i for i, val in enumerate(raw_Y) if val==1]\n",
        "axs[1].imshow(rgb_tensor[np.random.choice(neg_class,1)[0]])\n",
        "axs[1].set_title('neg frame ' + str(np.random.choice(neg_class,1)[0]))\n",
        "axs[2].imshow(rgb_tensor[np.random.choice(pos_class,1)[0]])\n",
        "axs[2].set_title('pos frame ' + str(np.random.choice(pos_class,1)[0]))\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-c902cbaa41a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Look at the distribution of classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class distribution'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'raw_Y' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LyI6trlu0IN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot first 25 trials and see what they look like \n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(rgb_tensor[i])\n",
        "    plt.xlabel(str(raw_Y[i]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNlmNktD5flN",
        "colab_type": "text"
      },
      "source": [
        "#3) Feature engineering and test/train splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8isaD7QviHex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3) Feature engineering and train test split\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = ms.train_test_split(rgb_tensor.numpy(), raw_Y , test_size=0.2)\n",
        "X_train,X_val,Y_train,Y_val= ms.train_test_split(X_train, Y_train, test_size=0.2)\n",
        "\n",
        "print('train = ' + str(X_train.shape[0]))\n",
        "print('test = ' + str(X_val.shape[0]))\n",
        "print('validation = ' + str(X_test.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4w-An99-cWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53db5170-18b8-48c6-fc7a-2979c818e6b4"
      },
      "source": [
        "rebalance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.65301492, 2.13382757])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC-FjSRQnzSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model prediction\n",
        "\n",
        "prediction = model.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDLbRuvJ8mg4",
        "colab_type": "text"
      },
      "source": [
        "#5) Hyperparameter tuning of best base model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCFirRoha_Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fine-tuning model by unfreezing layers and allowing them to be trainable\n",
        "\n",
        "model.trainable = True\n",
        "\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False\n",
        "\n",
        "# Compile model with specific metrics\n",
        "# Metrics below are for evaluating imbalanced datasets\n",
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name = 'auc')\n",
        "]\n",
        "\n",
        "# compile model with a much slower learning rate \n",
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=METRICS)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vjSTEJRmrmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit model with class imbalance weighting\n",
        "\n",
        "rebalance = class_weight.compute_class_weight('balanced',\n",
        "                                  np.unique(Y_train), Y_train.flatten())\n",
        "class_weights = {i : rebalance[i] for i in range(2)}\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=10,\n",
        "              validation_data=(X_val, Y_val),\n",
        "              class_weight=class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpJVra0Tga-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_Y = model.predict(rgb_tensor)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctihSG49mwz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fail_pred = raw_Y == pred_Y\n",
        "# tmp3 = \n",
        "tmp3 = np.argwhere(fail_pred==False)\n",
        "\n",
        "tmp3[:, 0]\n",
        "# print(fail_pred)\n",
        "print(raw_Y[1:10])\n",
        "print(pred_Y[1:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT-9itTmptWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdMS2pitI5uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "num_in_each = [1, 233, 430, 2008, 600, 1, 40]\n",
        "max_batch_size = 600\n",
        "cnt = 0\n",
        "extract_inds = []\n",
        "# num_in_each contains the number of frames in each file I am loading, ie\n",
        "# for trial/file 1 there are 200 frames , trial/file 2 has 215 frames etc\n",
        "for k, elem in enumerate(num_in_each) :\n",
        "  tot_frame_nums = sum(num_in_each[cnt: k+1]) # used to test if the number of frames in \n",
        "  # all these files exceded the \"max_batch_size\" limit \n",
        "  if tot_frame_nums>max_batch_size or len(num_in_each)-1 == k: # condition met, these files together \n",
        "  # meet the max requirment to load together as a batch \n",
        "    print(tot_frame_nums)\n",
        "    print(cnt, k+1)\n",
        "    extract_inds.append([cnt, k+1])\n",
        "    cnt = k+1 # reset to the current iter\n",
        "    if np.diff(extract_inds[-1]) > 1: # if there is more than one file then we want to take off the last file \n",
        "    # because it excedes the set number of frames\n",
        "      extract_inds[-1][-1] = extract_inds[-1][-1]-1\n",
        "      cnt = cnt-1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}