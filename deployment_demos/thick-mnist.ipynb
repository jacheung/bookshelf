{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84fc31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import mlflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32db4af5",
   "metadata": {},
   "source": [
    "## MLFlow\n",
    "MLFLow has 4 different applications: Tracking, Registry, Models, Projects. In this script, we'll demo all 4 via a local environment. \n",
    "1. Tracking: we will log hyper-parameters used and metrics for a transfer-learning model tuned to MNIST.  \n",
    "2. Registry: after our tuned model is identified, we will register our model. \n",
    "3. Models: a stored model must be served to deliver value. Models will be leveraged for inference. \n",
    "4. Projects: DS code is packaged to reproduce runs on any platform/machine via Projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6586651e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/jcheung/Documents/GitHub/bookshelf/deployment_demos/mlruns'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_tracking_uri()  \n",
    "# mlflow.set_tracking_uri('http://mlflow-server.kubeflow.svc.cluster.local:5000')  \n",
    "# mlflow.set_registry_uri('http://minio.kubeflow.svc.cluster.local:9000')  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "421a36b2",
   "metadata": {},
   "source": [
    "### First we'll build all the functions for our ML pipeline.\n",
    "This'll include functions for data loading, preprocessing, and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9162be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensorflow_dataset(dataset_str: str):\n",
    "    (xy_train, xy_test), ds_info = tfds.load(\n",
    "        dataset_str,\n",
    "        split=['train', 'test'], shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "    return (xy_train, xy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999038d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mnist_tfds(image, label=None):\n",
    "    # reshape and upsample to 3 channel for transfer learning models\n",
    "    # ... for when no channel information is present\n",
    "    if len(image.shape) != 3:\n",
    "        image = np.dstack((image, image, image))\n",
    "    # ... for when channel is only 1 dimension\n",
    "    if image.shape[2] == 1:\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "    # normalize pixel values\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    # resize with pad for mobilenetv2\n",
    "    image = tf.image.resize_with_pad(image, target_height=224, target_width=224)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aef92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(mlflow.pyfunc.PythonModel):     \n",
    "    def fit(self, xy_tuple_train, xy_tuple_test, hyperparameters):\n",
    "        ## Build model\n",
    "        # class names for mnist hardcoded\n",
    "        class_names = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    \n",
    "        # set layer regularization for DNN\n",
    "        regularizer = tf.keras.regularizers.l1_l2(hyperparameters['l1'], hyperparameters['l2'])\n",
    "\n",
    "        # load in mobilenetv2 weights and instantiate dense classification head \n",
    "        base_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "        layers = [\n",
    "            hub.KerasLayer(\n",
    "                base_model,\n",
    "                input_shape=(224, 224, 3),\n",
    "                trainable=False,\n",
    "                name='mobilenet_embedding'),\n",
    "            tf.keras.layers.Dense(hyperparameters['num_hidden'],\n",
    "                                  kernel_regularizer=regularizer,\n",
    "                                  activation='relu',\n",
    "                                  name='dense_hidden'),\n",
    "            tf.keras.layers.Dense(len(class_names),\n",
    "                                  kernel_regularizer=regularizer,\n",
    "                                  activation='softmax',\n",
    "                                  name='mnist_prob')\n",
    "        ]\n",
    "\n",
    "        self._model = tf.keras.Sequential(layers, name='mnist-classification')\n",
    "\n",
    "        # compile model \n",
    "        self._model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hyperparameters['learning_rate']),\n",
    "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                            from_logits=False),\n",
    "                            metrics=['accuracy'])\n",
    "                      \n",
    "        ## Fit model\n",
    "        # fit model and save history to model store\n",
    "        self._train_history = self._model.fit(xy_tuple_train, epochs=hyperparameters['epochs'], validation_data=xy_tuple_test)\n",
    "        self._model_base = base_model\n",
    "        \n",
    "    def predict(self, context, model_input: np.ndarray) -> np.ndarray:\n",
    "        image, _ = preprocess_mnist_tfds(model_input)\n",
    "        image = tf.reshape(image, [1, 224, 224, 3])\n",
    "        return self._model.predict(image).argmax()\n",
    "\n",
    "\n",
    "                            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d567d8d",
   "metadata": {},
   "source": [
    "### Tracking your model\n",
    "#### MLFlow has two levels for organizing projects:\n",
    "1. At the top level we have \"experiments\". These should be named as \"project-task-version\" (e.g. mnist-classification)\n",
    "2. At the lower level we have \"runs\". A run consists of logging hyperparameters and metrics when models are trained. Multiple runs can be stored within an experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b9ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment already exists, setting experiment to mnist-classification\n",
      "---------------------\n",
      "Experiment details are:\n",
      "Name: mnist-classification\n",
      "Experiment_id: 661060572347012195\n",
      "Artifact Location: file:///Users/jcheung/Documents/GitHub/bookshelf/deployment_demos/mlruns/661060572347012195\n",
      "Creation timestamp: 1684258817271\n"
     ]
    }
   ],
   "source": [
    "# mlflow Tracking requires definition of experiment name AND logged params\n",
    "# Experiment names they should be defined as \"project-task-version\"\n",
    "\n",
    "def set_mlflow_experiment(experiment_name:str):\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    except mlflow.exceptions.MlflowException as e: \n",
    "        if str(e) == f\"Experiment '{experiment_name}' already exists.\":\n",
    "            print(f'Experiment already exists, setting experiment to {experiment_name}')\n",
    "            experiment_info = mlflow.set_experiment(experiment_name)\n",
    "            experiment_id = experiment_info.experiment_id\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "    print(\"---------------------\")\n",
    "    print('Experiment details are:')\n",
    "    print(\"Name: {}\".format(experiment.name))\n",
    "    print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "    print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "    print(\"Creation timestamp: {}\".format(experiment.creation_time))\n",
    "    return experiment_id\n",
    "\n",
    "\n",
    "experiment_name = \"mnist-classification\"\n",
    "experiment_id = set_mlflow_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10969a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 14:05:05.985743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# preprocess and define batch sizes for tensorflow \n",
    "ds_train, ds_test = load_tensorflow_dataset('mnist')\n",
    "model = MNIST()\n",
    "ds_train = ds_train.map(preprocess_mnist_tfds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_test = ds_test.map(preprocess_mnist_tfds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74397177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# log a base model \n",
    "hyperparams = {\n",
    "    'learning_rate': 0.01,\n",
    "    'l1': 0.0,\n",
    "    'l2': 0.0, \n",
    "    'num_hidden': 16,\n",
    "    'epochs': 10}\n",
    "\n",
    "# Good practice to explicitly define experiment_id and run_name. \n",
    "# Experiment_id can be extracted from above. \n",
    "# Run name examples (e.g. Linear Regression Default Hyperparams).\n",
    "mlflow_run_name='MNIST Xfer Learning Base'\n",
    "with mlflow.start_run(experiment_id=experiment_id, \n",
    "                      run_name=mlflow_run_name) as run:\n",
    "    # You can set autolog for tensorflow model.\n",
    "    # Note that autolog does not allow logging of any additional params and metrics.\n",
    "    # We'll choose to do manual logging.\n",
    "    # mlflow.tensorflow.autolog()\n",
    "\n",
    "    model.fit(ds_train, ds_test, hyperparams)\n",
    "\n",
    "    # MLFlow Tracking parameters\n",
    "    mlflow.log_params(params=hyperparams)\n",
    "    \n",
    "    # MLFlow Tracking metrics \n",
    "    # Logging metrics for each epoch (housed in dictionary)\n",
    "    training_history = model._train_history.history\n",
    "    for epoch in range(0, hyperparams['epochs']):\n",
    "        insert = {}\n",
    "        for metric, value in training_history.items():\n",
    "            insert[metric] = training_history[metric][epoch]\n",
    "        mlflow.log_metrics(metrics=insert, step=epoch+1)\n",
    "\n",
    "    # MLFlow tracking artifact (e.g. model file)\n",
    "    # this will log the model and all its details under run_id/artifacts\n",
    "    mlflow.pyfunc.log_model(python_model=model,\n",
    "                           artifact_path=\"\")\n",
    "\n",
    "    # Close out MLFlow run to prevent any log contamination.\n",
    "    mlflow.end_run(status='FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53821fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "\n",
    "\n",
    "# hyperparameters search using Optuna\n",
    "# can scale Optuna with Kubernetes https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html\n",
    "def objective(trial): \n",
    "    \"\"\"\n",
    "    Optuna objective function for tuning transfer learning model\n",
    "    \"\"\"\n",
    "    hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.00001, 0.1, log=True),\n",
    "        'l1': trial.suggest_float('l1', 0.0, 0.05),\n",
    "        'l2': trial.suggest_float('l2', 0.0, 0.05),\n",
    "        'num_hidden': trial.suggest_int('num_hidden', 8, 64),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 3)\n",
    "    }\n",
    "\n",
    "    model.fit(ds_train, ds_test, hyperparams)\n",
    "    training_history = model._train_history.history\n",
    "    validation_accuracy = training_history['val_accuracy'][-1]\n",
    "    return validation_accuracy\n",
    "\n",
    "POSTGRES_DB=\"optunadb\"\n",
    "POSTGRES_USER=\"postgres\"\n",
    "POSTGRES_PASSWORD=\"mysecretpassword\"\n",
    "\n",
    "optuna_study_name = \"mnist-hyperparam-optuna\"\n",
    "optuna_storage_url=\"postgresql://{}:{}@localhost:5432/{}\".format(\n",
    "            POSTGRES_USER,\n",
    "            POSTGRES_PASSWORD,\n",
    "            POSTGRES_DB,\n",
    "           )\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3cd32bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading study...\n",
      "Experiment already exists, setting experiment to mnist-hyperparam-optuna\n",
      "---------------------\n",
      "Experiment details are:\n",
      "Name: mnist-hyperparam-optuna\n",
      "Experiment_id: 828443912064422063\n",
      "Artifact Location: file:///Users/jcheung/Documents/GitHub/bookshelf/deployment_demos/mlruns/828443912064422063\n",
      "Creation timestamp: 1684789437575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/0g6mnyq964z2cp592lvzfn480000gr/T/ipykernel_17144/3849037803.py:25: ExperimentalWarning: MLflowCallback is experimental (supported from v1.4.0). The interface can change in the future.\n",
      "  callbacks=[MLflowCallback(metric_name=\"val_accuracy\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Epoch 1/3\n",
      "469/469 [==============================] - 1124s 2s/step - loss: 16.3877 - accuracy: 0.2699 - val_loss: 14.6970 - val_accuracy: 0.2637\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 14:24:59.692933: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1125s 2s/step - loss: 14.9117 - accuracy: 0.2604 - val_loss: 14.6109 - val_accuracy: 0.3203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 14:25:00.591611: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "469/469 [==============================] - 1179s 3s/step - loss: 14.6693 - accuracy: 0.2444 - val_loss: 15.0822 - val_accuracy: 0.1637\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 14:44:38.589534: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1179s 3s/step - loss: 14.7386 - accuracy: 0.2917 - val_loss: 15.0392 - val_accuracy: 0.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 14:44:39.806320: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "\u001b[32m[I 2023-05-22 14:44:40,015]\u001b[0m Trial 3 finished with value: 0.171875 and parameters: {'learning_rate': 0.014223893963149662, 'l1': 0.014245541974730658, 'l2': 0.0016850673824220952, 'num_hidden': 53, 'epochs': 2}. Best is trial 3 with value: 0.171875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/469 [..............................] - ETA: 12:47 - loss: 14.5965 - accuracy: 0.1703Epoch 1/2\n",
      "469/469 [==============================] - 1343s 3s/step - loss: 3.7989 - accuracy: 0.3112 - val_loss: 3.4046 - val_accuracy: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-22 15:07:01,292]\u001b[0m Trial 2 finished with value: 0.33000001311302185 and parameters: {'learning_rate': 0.0013152206245103755, 'l1': 0.03420949059716998, 'l2': 0.03420202783177966, 'num_hidden': 55, 'epochs': 3}. Best is trial 2 with value: 0.33000001311302185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "469/469 [==============================] - 1352s 3s/step - loss: 11.5334 - accuracy: 0.3341 - val_loss: 3.1609 - val_accuracy: 0.2148\n",
      "Epoch 2/2\n",
      "469/469 [==============================] - 984s 2s/step - loss: 2.0485 - accuracy: 0.8531 - val_loss: 1.5767 - val_accuracy: 0.8747\n",
      "Epoch 2/2\n",
      "469/469 [==============================] - 976s 2s/step - loss: 2.7079 - accuracy: 0.2063 - val_loss: 2.4202 - val_accuracy: 0.1970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-22 15:23:34,462]\u001b[0m Trial 4 finished with value: 0.19699999690055847 and parameters: {'learning_rate': 0.00037088602731549493, 'l1': 0.03582313814836442, 'l2': 0.031066266126062538, 'num_hidden': 35, 'epochs': 2}. Best is trial 2 with value: 0.33000001311302185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/469 [..............................] - ETA: 11:19 - loss: 1.5307 - accuracy: 0.9031Epoch 1/3\n",
      "469/469 [==============================] - 1159s 2s/step - loss: 1.5586 - accuracy: 0.8752 - val_loss: 1.5274 - val_accuracy: 0.8676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-22 15:42:49,274]\u001b[0m Trial 5 finished with value: 0.8676000237464905 and parameters: {'learning_rate': 0.004585944413795202, 'l1': 0.004306427884085057, 'l2': 0.03147947959667124, 'num_hidden': 57, 'epochs': 2}. Best is trial 5 with value: 0.8676000237464905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "469/469 [==============================] - 1169s 2s/step - loss: 26.4783 - accuracy: 0.2594 - val_loss: 25.1087 - val_accuracy: 0.2854\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 1272s 3s/step - loss: 2.7553 - accuracy: 0.5715 - val_loss: 2.4206 - val_accuracy: 0.5764\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 1262s 3s/step - loss: 24.7966 - accuracy: 0.2835 - val_loss: 25.9264 - val_accuracy: 0.2977\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 1177s 3s/step - loss: 2.5697 - accuracy: 0.6093 - val_loss: 2.4137 - val_accuracy: 0.6191\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 1176s 3s/step - loss: 24.7826 - accuracy: 0.2873 - val_loss: 24.3571 - val_accuracy: 0.3067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-22 16:23:45,738]\u001b[0m Trial 6 finished with value: 0.3066999912261963 and parameters: {'learning_rate': 0.054938474710103505, 'l1': 0.03807304604405147, 'l2': 0.03952002131195158, 'num_hidden': 64, 'epochs': 3}. Best is trial 5 with value: 0.8676000237464905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/469 [..............................] - ETA: 9:20 - loss: 2.4503 - accuracy: 0.6016Epoch 1/3\n",
      "469/469 [==============================] - 949s 2s/step - loss: 2.4074 - accuracy: 0.6224 - val_loss: 5.0861 - val_accuracy: 0.2849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-22 16:39:34,180]\u001b[0m Trial 7 finished with value: 0.2849000096321106 and parameters: {'learning_rate': 0.07387083227571944, 'l1': 0.0035029390922733774, 'l2': 0.0405698172447872, 'num_hidden': 16, 'epochs': 3}. Best is trial 5 with value: 0.8676000237464905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "469/469 [==============================] - 958s 2s/step - loss: 41.8288 - accuracy: 0.2604 - val_loss: 26.9907 - val_accuracy: 0.3723\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 3985s 8s/step - loss: 3.8757 - accuracy: 0.7218 - val_loss: 2.2209 - val_accuracy: 0.7551\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 3977s 8s/step - loss: 17.0162 - accuracy: 0.4443 - val_loss: 9.2888 - val_accuracy: 0.5459\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 1023s 2s/step - loss: 2.1538 - accuracy: 0.7776 - val_loss: 2.0959 - val_accuracy: 0.7753\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 1023s 2s/step - loss: 5.9656 - accuracy: 0.4981 - val_loss: 4.5129 - val_accuracy: 0.4071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-22 18:03:08,052]\u001b[0m Trial 8 finished with value: 0.40709999203681946 and parameters: {'learning_rate': 5.2511164706452605e-05, 'l1': 0.04592869983425784, 'l2': 0.03711551553729608, 'num_hidden': 26, 'epochs': 3}. Best is trial 5 with value: 0.8676000237464905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 687s 1s/step - loss: 2.0809 - accuracy: 0.7841 - val_loss: 2.0691 - val_accuracy: 0.7850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-22 18:14:31,956]\u001b[0m Trial 9 finished with value: 0.7850000262260437 and parameters: {'learning_rate': 0.002059020032901681, 'l1': 0.016432402736181007, 'l2': 0.025630669313396637, 'num_hidden': 56, 'epochs': 3}. Best is trial 5 with value: 0.8676000237464905.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('loading study...')\n",
    "    study = optuna.load_study(\n",
    "        study_name=optuna_study_name,\n",
    "        storage=optuna_storage_url,\n",
    "    )\n",
    "    \n",
    "except KeyError:\n",
    "    print('no study found. building from scratch...')\n",
    "    study = optuna.create_study(\n",
    "        study_name=optuna_study_name,\n",
    "        storage=optuna_storage_url,\n",
    "        pruner=optuna.pruners.HyperbandPruner(),\n",
    "        direction='maximize')\n",
    "\n",
    "\n",
    "# create or set an experiment for optuna. Each trial from Optuna is logged as one run in an MLFlow experiment.\n",
    "experiment_id = set_mlflow_experiment(experiment_name=optuna_study_name)\n",
    "mlflow_kwargs = {'experiment_id': experiment_id}\n",
    "\n",
    "# a new experiment name will be created in MLFlow using the Optuna study name\n",
    "study.optimize(objective,\n",
    "               n_trials=8,\n",
    "               n_jobs=2,\n",
    "              callbacks=[MLflowCallback(metric_name=\"val_accuracy\",\n",
    "                                        create_experiment=False,\n",
    "                                        mlflow_kwargs=mlflow_kwargs)]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f915bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log the hyper parameter tuned model \n",
    "# No need to set experiment ID if you've set above. \n",
    "# Set a run name here(e.g. Linear Regression Default Hyperparams).\n",
    "mlflow_run_name='MNIST Xfer Learning Hyperparam tuned'\n",
    "with mlflow.start_run(experiment_id=experiment_id, \n",
    "                      run_name=mlflow_run_name) as run:\n",
    "    \n",
    "    model.train(ds_train, ds_test, hyperparams)\n",
    "\n",
    "    # MLFlow Tracking parameters\n",
    "    mlflow.log_params(params=hyperparams)\n",
    "    \n",
    "    # MLFlow Tracking metrics \n",
    "    # Logging metrics for each epoch (housed in dictionary)\n",
    "    training_history = model._train_history.history\n",
    "    for epoch in range(0, hyperparams['epochs']):\n",
    "        insert = {}\n",
    "        for metric, value in training_history.items():\n",
    "            insert[metric] = training_history[metric][epoch]\n",
    "        mlflow.log_metrics(metrics=insert, step=epoch+1)\n",
    "\n",
    "    # MLFlow tracking artifact (e.g. model file)\n",
    "    # mlflow.log_artifact(self._model)\n",
    "\n",
    "    # we need to define how we use tags for testing or if we even need them...\n",
    "    mlflow.set_tag(key=\"test\",\n",
    "                   value=\"manual-logging\")\n",
    "\n",
    "    mlflow.end_run(status='FINISHED')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54fe297d",
   "metadata": {},
   "source": [
    "### Registering your model\n",
    "Once you've run a couple experiments (e.g. hyper parameter tuning) we can select the best model and register that. Model registering just means that we decide this our optimized model to save. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ec055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search runs \n",
    "filtering_clause = 'params.epochs = \"10\" and params.learning_rate = \"0.01\"'\n",
    "run = mlflow.search_runs(\n",
    "    experiment_names=['mnist-classification'],\n",
    "    filter_string=filtering_clause,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.val_accuracy DESC\"],\n",
    ")\n",
    "\n",
    "# best performing model run_id. This'll be used to register our model\n",
    "best_run_id = run['run_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register model after a scanning a couple different runs from your experiment \n",
    "model_name = f'{experiment.name}'\n",
    "# mlflow.tensorflow.log_model\n",
    "mv = mlflow.register_model(model_uri=f\"runs:/{best_run_id}/\",\n",
    "                           name=model_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b5c3143",
   "metadata": {},
   "source": [
    "### Serving model\n",
    "After we've registered our model, we can now test inference for that model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9493c05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load directly from registry \n",
    "# model_version=1\n",
    "# model_name = f'{experiment.name}'\n",
    "# model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
    "\n",
    "# load using artifact path directory\n",
    "results = mlflow.search_registered_models(filter_string='name = \"mnist-classification\"')\n",
    "latest_model_details = results[0].latest_versions[0]\n",
    "model = mlflow.pyfunc.load_model(model_uri=f'{latest_model_details.source[7:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample and load a MNIST JPEG\n",
    "import os \n",
    "from random import sample\n",
    "from PIL import Image\n",
    "fp = '/Users/jcheung/Documents/GitHub/thin-ML-deployment/app/ml/test_images'\n",
    "files = [f'{fp}/{x}' for x in os.listdir(fp) if x.split('.')[-1] == 'jpg']\n",
    "filename = sample(files, 1)[0]\n",
    "image = np.array(Image.open(filename))\n",
    "\n",
    "# predict using custom mlflow model\n",
    "predicted = model.predict(image)\n",
    "\n",
    "# output and compare results\n",
    "true = filename.split('/')[-1].split('_')[-1][0]\n",
    "\n",
    "print(f'True:{true} and predicted:{predicted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e10b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61cd631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kubeflow.katib as katib\n",
    "\n",
    "# Step 1. Create an objective function.\n",
    "def objective(hyperparams):\n",
    "    training_history = model.train(ds_train, ds_test, hyperparams)\n",
    "    validation_accuracy = training_history.history['val_accuracy'][-1]\n",
    "    # Katib parses metrics in this format: <metric-name>=<metric-value>.\n",
    "    print(f\"result={result}\")\n",
    "\n",
    "# Step 2. Create HyperParameter search space.\n",
    "hyperparams = {\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.00001, 0.1, log=True),\n",
    "    'l1': trial.suggest_float('l1', 0.0, 1),\n",
    "    'l2': trial.suggest_float('l2', 0.0, 1),\n",
    "    'num_hidden': katib.search.int(min=8, max=64),\n",
    "    'epochs': katib.search.int(min=5, max=10)\n",
    "}\n",
    "\n",
    "hyperparams = {\n",
    "    \"a\": katib.search.int(min=10, max=20),\n",
    "    \"b\": katib.search.double(min=0.1, max=0.2)\n",
    "}\n",
    "\n",
    "# Step 3. Create Katib Experiment.\n",
    "katib_client = katib.KatibClient()\n",
    "name = \"tune-experiment\"\n",
    "katib_client.tune(\n",
    "    name=name,\n",
    "    objective=objective,\n",
    "    parameters=parameters,\n",
    "    objective_metric_name=\"result\",\n",
    "    max_trial_count=12\n",
    ")\n",
    "\n",
    "# Step 4. Get the best HyperParameters.\n",
    "print(katib_client.get_optimal_hyperparameters(name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thick-ML-deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
